---
title: "ECS で小さく始める OpenTelemetry 構成"
emoji: "🐥"
type: "tech" # tech: 技術記事 / idea: アイデア
topics: ["opentelemetry", "grafana", "aws", "ecs"]
published: true
---

こんにちは。  
ご機嫌いかがでしょうか。  
"No human labor is no human error" が大好きな[吉井 亮](https://twitter.com/YoshiiRyo1)です。  

なにごとも小さく始めて成功体験を積み上げながら大きくしていくのが良いと思います。  
Observability についても同じ考えです。  

これから Observability を導入する方の助けになればと思い、ECS で小さく始める OpenTelemetry 構成をご紹介します。  


## 構成

アプリケーションに OpenTelemetry SDK を組み込み、トレースとメトリクスを OpenTelemetry Collector に送信します。  
アプリケーションのログは CloudWatch Logs に送信します。  

OpenTelemetry Collector は独立したコンテナです。サイドカーという選択肢もあるかと思います。  
OpenTelemetry Collector は Tempo にトレースを送信し、Prometheus にメトリクスを送信します。  

Prometheus は Mimir を経由して受信したデータを S3 に保存します。  

可視化は Grafana で行います。  

全てのコンテナは ECS on Fargate で動作しています。  

![img](/images/0552d3c8dcca6a.drawio.png)


## OpenTelemetry Collector

コンポーネントごとに設定を解説します。  

receiver は otlp のみを使用しています。  

extensions → health_check は ECS タスクの生存確認に利用しています。  
サイドカーコンテナから `curl localhost:13133/` を数秒おきに実行し続けています。  

processors → filter で `/health` へのリクエストはトレースとして受け付けないようにしています。  
本当はアプリケーションの OpenTelemetry SDK 計装で除外できれば良かったのですが、アプリケーションコードに本来機能以外の記述をたくさん書くのは避けたいのでこうしました。  

exporters には Tempo と Prometheus に送信する設定を記述しています。  

::::details クリックして展開
```yaml
receivers:
  otlp:
    protocols:
      grpc:
        endpoint: ${env:HOSTNAME}:4317

extensions:
  health_check: {}

processors:
  batch: {}

  memory_limiter:
    check_interval: 5s
    limit_percentage: 80
    spike_limit_percentage: 25

  filter:
    error_mode: ignore
    traces:
      span:
        - attributes["http.target"] == "/health"

exporters:
  debug:

  otlp/tempo:
    endpoint: tempo.my-local-domain:4317
    tls:
      insecure: true

  prometheusremotewrite:
    endpoint: "https://prometheus.my-local-domain:9090/api/v1/push"

service:
  extensions:
    - health_check

  pipelines:
    traces:
      receivers: [otlp]
      processors: [memory_limiter, filter, batch]
      exporters: [otlp/tempo, debug]
    metrics:
      receivers: [otlp]
      processors: [memory_limiter, batch]
      exporters: [prometheusremotewrite, debug]
```
::::

## Prometheus

Prometheus は特になにも設定はしていません。Mimir の送信先のみです。  

::::details クリックして展開
```yaml
remote_write:
  - url: http://mimir.my-local-domain:8080/api/v1/push
```
::::

## Tempo

Tempo は All In One 型のコンテナイメージを使用しています。システム全体が中規模以上になってくるようならマイクロサービス型の構成を検討するつもりです。  

[metrics_generator](https://grafana.com/docs/tempo/latest/metrics-generator/) は今回どうしても導入したかった機能です。  
トレースからメトリクスを生成する機能です。  
overrides で機能を有効化しています。  

storage は S3 を使用しています。  

compactor で 720 時間以上前のデータを削除する設定をしています。トレースをログやメトリクスを関連付けている場合は期間を合わせて設定します。  

::::details クリックして展開
```yaml
distributor:
  receivers:
    otlp:
      protocols:
        grpc: 
          endpoint: 0.0.0.0:4317

ingester:
  flush_all_on_shutdown: true

server:
  http_listen_port: 8080

metrics_generator:
  storage:
    remote_write:
      - url: http://prometheus.my-local-domain:9090/api/v1/write
        send_exemplars: true
    path: /var/tempo/generator/wal

compactor:
  compaction:
    block_retention: 720h

storage:
  trace:
    backend: s3
    wal:
      path: /var/tempo/wal 
    s3:
      bucket: My_Bucket_Name
      endpoint: s3.ap-northeast-1.amazonaws.com
      region: ap-northeast-1

overrides:
  defaults:
    metrics_generator:
     processors: ["service-graphs", "span-metrics"]
```
::::

## Mimir

storage は S3 を使用しています。Tempo とはそれぞれ別のバケットを使用しています。  
あとはテンプレート通りで、特にこれといった設定はしていません。  

::::details クリックして展開
```yaml
target: all

activity_tracker:
  filepath: "/data/metrics-activity.log"

common:
  storage:
    backend: s3
    s3:
      bucket_name: My_Bucket_Name
      endpoint: s3.ap-northeast-1.amazonaws.com
      region: ap-northeast-1

ruler:
  rule_path: /data/data-ruler/

ruler_storage:
  storage_prefix: ruler

alertmanager:
  sharding_ring:
    replication_factor: 1

alertmanager_storage:
  storage_prefix: alertmanager

blocks_storage:
  storage_prefix: blocks
  bucket_store:
    sync_dir: /data/tsdb-sync/
  tsdb:
    dir: /data/tsdb/

compactor:
  data_dir: /data/data-compactor/

limits:
  compactor_blocks_retention_period: 30d

store_gateway:
  sharding_ring:
    replication_factor: 1

ingester:
  ring:
    replication_factor: 1
```
::::

## 宿題

トレースとログの関連付けができていません。  
CloudWatch Logs にコンテナログを保存しているところのツラミが少々ありまして。。。  
Loki を追加して Loki にログを送ると個人的には楽になると思っていますが、自分だけがログを見るわけではないのでバランスが必要です。  

メトリクスが全くと言っていいほど取得できていません。  
OpenTelemetry Collector をサイドカーにして、様々なメトリクスを取得することを検討しています。  
